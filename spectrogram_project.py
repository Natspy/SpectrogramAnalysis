# -*- coding: utf-8 -*-
"""AS_PROJEKT_1

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mh4qjwV1BE20dhSMXC5C5fgNrdWoAyOr

# Projekt 1 - Analiza Sygnałów - Natalia Karczewska

## 1. Wczytanie danych oraz wstępne obserwacje

Na początek wczytuję dwa fragmenty utworów audio, zapisanych w formacie wav. Linki do plików znajdują się poniżej:

* [Candy_Dulfer_-_Lily_Was_Here.wav](https://drive.google.com/open?id=0B7k6Z_ViZid5WXc0WVQ4U0d2TVk) (sygnał 1)
* [Rupert_Blaise_-_06_-_What_A_Wonderful_World.wav](https://drive.google.com/open?id=0B7k6Z_ViZid5U193d2Rqc2xJdG8)
(sygnał 2)

Następnie obliczam czas trwania sygnałów, po czym wyświetlam je na wykresie, aby obejrzeć ich przebieg.
"""

import numpy as np
import matplotlib.pyplot as plt
import numpy.fft as fft
import scipy.io
from scipy.io import wavfile
import scipy.signal as ss

Fs, syg_1 = wavfile.read('Candy_Dulfer_-_Lily_Was_Here.wav')
Fs, syg_2 = wavfile.read('Rupert_Blaise_-_06_-_What_A_Wonderful_World.wav')
# Oba sygnały mają tę samą długość oraz częstość próbkowania;

T = len(syg_1)/Fs
print('Czas trwania sygnałów:',T,'s')
dt = 1/Fs
t = np.arange(0,T,dt)

plt.plot(t, syg_1)
plt.xlabel('Czas [s]')
plt.ylabel('Amplituda')
plt.title('"Candy Dulfer - Lily Was Here"')
plt.show()

plt.plot(t, syg_2)
plt.xlabel('Czas [s]')
plt.ylabel('Amplituda')
plt.title('"Rupert Blaise - What A Wonderful World"')
plt.show()

"""We fragmencie utworu z sygnału pierwszego grają jedynie instrumenty, natomiast w sygnale drugim mamy do czynienia z ludzkim śpiewem. Już na pierwszy rzut oka widzimy pewne różnice w przebiegu sygnałów (w drugim utworze występują dwukrotnie wyższe amplitudy), które prawdopodobnie w kolejnych krokach mogą pozwolić nam odróżnić dźwięk instrumentu od głosu ludzkiego. Dokładniej przekonamy się o tym, tworząc **spektrogram**. Stanowi on reprezentację rozkładu energii sygnału w dziedzinie czas-częstość.

## 2. Implementacja spektrogramu

**Spektrogram** składa się z szeregu widm okienkowanych, wyznaczanych dla pewnych odcinków sygnału, których długość oznaczymy jako **N_okna**. Następnie wyliczone widma ustawiamy kolejno obok siebie (mogą one na siebie nachodzić - szerokość nachodzących fragmentów oznaczymy jako **N_wsp**). Estymację widma wykonamy obliczając widmo decybelowe z okienkiem **okno**, ponieważ w wyniku porównań i obliczeń doszłam do wniosku, że daje on bardziej przejrzyste wyniki niż periodogram. Widma kolejnych fragmentów zapiszę w macierzy w taki sposób, że i-ta kolumna będzie zawierać widmo i-tego fragmentu sygnału.

### Potrzebne funkcje:
"""

# Tworzę funkcję obliczającą widmo decybelowe dla pojedyńczego fragmentu zokienkowanego sygnału;

def widmo_dB(syg_samp, okno, Fs):
    N = len(syg_samp)
    syg_samp = syg_samp*(okno/np.linalg.norm(okno))
    Syg_samp = fft.rfft(syg_samp, N)
    S_dB = 20*np.log10(np.abs(Syg_samp))
    return S_dB

# Funkcja dzieląca sygnał na fragmenty:

def podziel(syg, N_okna, N_wsp):
    N = len(syg)
    start, stop = 0, N_okna
    result = []
    while stop <= N:
        result.append(syg[start:stop])
        start += N_okna - N_wsp
        stop += N_okna - N_wsp
    return result

# Zdaję sobie sprawę, że tablice numpy są optymalniejsze dla dużych zbiorów danych,
# niestety próbując wykonać na nich powyższe operacje otrzymywałam masę błędów, dlatego pozostałam przy listach;

# Wreszcie: funkcja obliczająca macierz widm potrzebną do wyrysowania spektrogramu;

def spektrogram(syg, N_okna, N_wsp, okno, t_min, t_max):
    samples = podziel(syg ,N_okna,N_wsp)
    wycinek_czasu = samples[int((len(samples)/T)*t_min):int((len(samples)/T)*t_max)]
    widma = [widmo_dB(i,okno,Fs) for i in wycinek_czasu]
    result = np.transpose(np.matrix(widma))
    return result

"""### Rysowanie spektrogramów"""

# Lily Was Here 

# Dane przeznaczone do zmian:

N_okna = Fs//10
N_wsp = 0
okno = np.hanning(N_okna)
t_min = 0.0
t_max = T
f_min = 0.0
f_max = N_okna

# Spektrogram:

plt.imshow(spektrogram(syg_1, N_okna, N_wsp, okno, t_min, t_max), origin='lower', aspect='auto', extent=(t_min, t_max, 0.0 ,N_okna), interpolation='nearest')
plt.title('"Candy Dulfer - Lily Was Here" z oknem Hanna')
plt.xlabel('Czas [s]')
plt.ylabel('Częstotliwość')
plt.ylim(f_min, f_max)
plt.show()

# Testuję, czy wbudowana funkcja ss.spectrogram da podobny wynik do mojego;

f, t, Sxx = ss.spectrogram(syg_1, fs=Fs, window='hanning')
Sxx = 20 * np.log10(np.abs(Sxx)) # skala decybelowa
plt.imshow(Sxx, aspect='auto', origin='lower', extent=(t_min, t_max, f_min , f_max),interpolation='nearest')
plt.title('"Candy Dulfer - Lily Was Here" z oknem Hanna\nza pomocą funkcji wbudowanej ss.spectrogram')
plt.xlabel('Czas [s]')
plt.ylabel('Częstotliwość')
plt.ylim(f_min, f_max)

plt.show()

"""Wygląda na to, że funkcja wbudowana *scipy.signal.spectrogram* zgodnie z oczekiwaniami wyświetla spektrogram podobny do stworzonego poprzez samodzielną implementację.
Poniżej prezentuję porównanie spektrogramów utworu "*Candy Dulfer - Lily Was Here*" dla różnych długości **N_okna**:
"""

# Chcąc wybrać reprezentatywne długości N_okna, ustawiam je jako różne wielokrotności Fs;

plt.subplot(2,2,1)
plt.imshow(spektrogram(syg_1,Fs*2, N_wsp, np.hanning(Fs*2), t_min, t_max), origin='lower', aspect='auto', extent=(t_min, t_max, 0.0 ,N_okna), interpolation='nearest')
plt.title('N_okna = '+str(Fs*2))

plt.subplot(2,2,2)
plt.imshow(spektrogram(syg_1,Fs, N_wsp, np.hanning(Fs), t_min, t_max), origin='lower', aspect='auto', extent=(t_min, t_max, 0.0 ,N_okna), interpolation='nearest')
plt.title('N_okna = '+str(Fs))

plt.show()

plt.subplot(2,2,3)
plt.imshow(spektrogram(syg_1,Fs//2, N_wsp, np.hanning(Fs//2), t_min, t_max), origin='lower', aspect='auto', extent=(t_min, t_max, 0.0 ,N_okna), interpolation='nearest')
plt.title('N_okna = '+str(Fs//2))

plt.subplot(2,2,4)
plt.imshow(spektrogram(syg_1,Fs//10, N_wsp, np.hanning(Fs//10), t_min, t_max), origin='lower', aspect='auto', extent=(t_min, t_max, 0.0 ,N_okna), interpolation='nearest')
plt.title('N_okna = '+str(Fs//10))

plt.show()

# What A Wonderful World

# Dane przeznaczone do zmian:

N_okna_2 = Fs//10
N_wsp_2 = 0
okno_2 = np.hanning(N_okna_2)
t_min_2 = 0.0
t_max_2 = T
f_min_2 = 0.0
f_max_2 = N_okna_2

# Spektrogram:

plt.imshow(spektrogram(syg_2,N_okna_2, N_wsp_2, okno_2, t_min_2,t_max_2), origin='lower', aspect='auto', extent=(t_min_2, t_max_2, 0.0, N_okna_2),interpolation='nearest')
plt.title('"Rupert Blaise - What A Wonderful World" z oknem Hanna')
plt.xlabel('Czas [s]')
plt.ylabel('Częstotliwość')
plt.ylim(f_min_2, f_max_2)
plt.show()

""""*Rupert Blaise - What A Wonderful World*" dla różnych długości **N_okna**:"""

plt.subplot(2,2,1)
plt.imshow(spektrogram(syg_2,Fs*2, N_wsp_2, np.hanning(Fs*2), t_min_2, t_max_2), origin='lower', aspect='auto', extent=(t_min, t_max, 0.0 ,N_okna), interpolation='nearest')
plt.title('N_okna = '+str(Fs*2))

plt.subplot(2,2,2)
plt.imshow(spektrogram(syg_2,Fs, N_wsp_2, np.hanning(Fs), t_min_2, t_max_2), origin='lower', aspect='auto', extent=(t_min, t_max, 0.0 ,N_okna), interpolation='nearest')
plt.title('N_okna = '+str(Fs))

plt.show()

plt.subplot(2,2,3)
plt.imshow(spektrogram(syg_2,Fs//2, N_wsp_2, np.hanning(Fs//2), t_min_2, t_max_2), origin='lower', aspect='auto', extent=(t_min, t_max, 0.0 ,N_okna), interpolation='nearest')
plt.title('N_okna = '+str(Fs//2))

plt.subplot(2,2,4)
plt.imshow(spektrogram(syg_2,Fs//10, N_wsp_2, np.hanning(Fs//10), t_min_2, t_max_2), origin='lower', aspect='auto', extent=(t_min, t_max, 0.0 ,N_okna), interpolation='nearest')
plt.title('N_okna = '+str(Fs//10))

plt.show()

"""## 3. Interpretacja wyników
---

Im większą długość **N_okna** przyjmiemy przy tworzeniu widm, tym lepszą uzyskamy jego rozdzielczość w częstotliwości. Spektrogram uzyskany z takich widm również będzie miał bardzo dobrą rozdzielczość w domenie częstotliwości, jednak duży odstęp czasu pomiędzy kolejnymi fragmentami sygnału sprawi, że jego rozdzielczość w  czasie będzie niska. W drugą stronę działa to tak samo – stosując krótsze długości **N_okna** do stworzenia widma, uzyskamy świetną rozdzielczość czasową, ale słabszą jeśli chodzi o domenę częstotliwości. Trudno znaleźć udany kompromis rozdzielczościowy, w związku z czym spektrogramy możemy podzielić na dwa typy:
- **wąskopasmowe** (dobra rozdzielczość częstotliwościowa - większe długości **N_okna**).
- **szerokopasmowe** (dobra rozdzielczość w czasie - mniejsze długości **N_okna**).

---

Czy na podstawie takich spektrogramów jesteśmy w stanie odróżnić kiedy grał który instrument, a kiedy był to głos ludzki?

Biorąc pod uwagę widoczne różnice pomiędzy spektrogramami obu utworów oraz fakt, że w pierwszym z nich mamy do czynienia jedynie z dźwiękami instrumentów, natomiast w drugim pojawia się głos ludzki - mogę potwierdzić, że na ich podstawie jesteśmy w stanie rozpoznać źródło dźwięków. Dla pierwszego spektrogramu utworu "*What A Wonderful World*" wybrałam stosunkowo krótką długość **N_okna**, dzięki czemu uzyskałam wysoką rozdzielczość w czasie. Następnie odsłuchując utwór sekunda po sekundzie zaobserwowałam, że tam gdzie w utworze pojawia się ludzki śpiew (na przykład w 00:02, 00:08 lub 0:34) na spektrogramie w tym miejscu obserwujemy pionowy prążek szeroko rozciągnięty w obszarze częstotliwości, natomiast tam gdzie gra sam instrument, spektrogram jest zakolorowany na znacznie krótszym obszarze w pionie. W utworze "*Candy Dulfer - Lily Was Here*" występują tylko dźwięki instrumentów, w wyniku czego spektrogram jest zakolorowany na podobnym, dosyć stałym poziomie i najczęściej jedynie dźwięk struny gitary lub instrumentów dętych powoduje krótkie wyciągnięcia w pionie.

---

Czy na podstawie spektrogramów dałoby się określić tony podstawowe?

**Ton podstawowy** to fala harmoniczna o najmniejszej częstotliwości w szeregu harmonicznym. Tony podstawowe szczególnie dobrze możemy zaobserwować na spektrogramie utworu "*What A Wonderful World*". Występują one w dolnych partiach spektrogramu w postaci poziomych pasków o jasnym, żółtym zabarwieniu. Są to najniższe częstotliwości, jakie wydają instrumenty. Mimo to, silnie żółtą "podstawę" spektrogramu możemy zaobserwowac także w pierwszym utworze.

---

"""